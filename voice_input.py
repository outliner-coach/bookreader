#!/usr/bin/env python3
"""
ìŒì„± ì…ë ¥ ë„êµ¬
ë§ˆì´í¬ë¡œ ë…¹ìŒ â†’ Whisper ë³€í™˜ â†’ í´ë¦½ë³´ë“œ ë³µì‚¬
ì—”í„°ë¥¼ ëˆ„ë¥´ë©´ ë…¹ìŒ ì‹œì‘/ì¢…ë£Œ
"""

import sys
import tempfile
import numpy as np
import sounddevice as sd
import whisper
import pyperclip
from scipy.io import wavfile


# ì„¤ì •
SAMPLE_RATE = 16000  # Whisper ê¶Œì¥ ìƒ˜í”Œë ˆì´íŠ¸
MODEL_NAME = "medium"  # tiny, base, small, medium, large


def record_audio():
    """ì—”í„°ë¡œ ë…¹ìŒ ì‹œì‘/ì¢…ë£Œ"""
    print("\nğŸ¤ ì—”í„°ë¥¼ ëˆ„ë¥´ë©´ ë…¹ìŒ ì‹œì‘...")
    input()

    print("ğŸ”´ ë…¹ìŒ ì¤‘... (ì—”í„°ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œ)")

    # ë…¹ìŒ ë°ì´í„° ì €ì¥ìš©
    frames = []

    def callback(indata, frame_count, time_info, status):
        frames.append(indata.copy())

    # ë…¹ìŒ ì‹œì‘
    stream = sd.InputStream(
        samplerate=SAMPLE_RATE,
        channels=1,
        dtype=np.float32,
        callback=callback
    )

    with stream:
        input()  # ì—”í„° ëŒ€ê¸°

    print("â¹ï¸  ë…¹ìŒ ì¢…ë£Œ")

    # ë…¹ìŒ ë°ì´í„° í•©ì¹˜ê¸°
    if not frames:
        return None

    audio_data = np.concatenate(frames, axis=0)
    return audio_data


def transcribe(audio_data, model):
    """ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
        # float32ë¥¼ int16ìœ¼ë¡œ ë³€í™˜
        audio_int16 = (audio_data * 32767).astype(np.int16)
        wavfile.write(f.name, SAMPLE_RATE, audio_int16)
        temp_path = f.name

    # ë³€í™˜
    result = model.transcribe(temp_path, language="ko")

    # ì„ì‹œ íŒŒì¼ ì‚­ì œ
    import os
    os.unlink(temp_path)

    return result["text"].strip()


def main():
    print("=" * 50)
    print("ğŸ™ï¸  ìŒì„± ì…ë ¥ ë„êµ¬")
    print("=" * 50)
    print(f"ëª¨ë¸: {MODEL_NAME}")
    print("Ctrl+Cë¡œ ì¢…ë£Œ")
    print("=" * 50)

    print("\nëª¨ë¸ ë¡œë”© ì¤‘...")
    model = whisper.load_model(MODEL_NAME, device="cpu")
    print("ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")

    try:
        while True:
            # ë…¹ìŒ
            audio_data = record_audio()

            if audio_data is None or len(audio_data) < SAMPLE_RATE * 0.5:
                print("âš ï¸  ë…¹ìŒì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤.")
                continue

            # ë³€í™˜
            print("ğŸ”„ ë³€í™˜ ì¤‘...")
            text = transcribe(audio_data, model)

            if text:
                # í´ë¦½ë³´ë“œì— ë³µì‚¬
                pyperclip.copy(text)
                print(f"\nâœ… ë³€í™˜ ì™„ë£Œ (í´ë¦½ë³´ë“œì— ë³µì‚¬ë¨):")
                print(f"   \"{text}\"")
                print("\n   Cmd+Vë¡œ ë¶™ì—¬ë„£ê¸° í•˜ì„¸ìš”!")
            else:
                print("âš ï¸  ì¸ì‹ëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        sys.exit(0)


if __name__ == "__main__":
    main()
